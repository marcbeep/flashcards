---

## **Swarm Intelligence (SI)**

Swarm Intelligence is an approach to problem-solving inspired by the collective behavior of decentralized, self-organized systems—such as bird flocks or ant colonies. Key characteristics:

- **Local search**: Each agent (e.g., ant or particle) searches independently.
- **Global information sharing**: Through simple communication (like pheromone trails or shared best-known positions), agents influence one another.

### Examples:

- **Ant Systems**: Ants lay pheromone trails to share good paths.
- **Particle Swarm Optimization (PSO)**: Agents (particles) share their best-found solutions.

---

## **Origins of Particle Swarm Optimization (PSO)**

### **Inspiration: Flocking Behavior**

- Birds and fish move in coordinated groups through simple local rules.
- **Craig Reynolds’ Boids Model (1986)** simulates flocking using 3 key rules:

  1. **Separation** – Avoid crowding neighbors.
  2. **Alignment** – Match the velocity of neighbors.
  3. **Cohesion** – Move toward the average position of neighbors.

### **Kennedy & Eberhart’s Extension (1995)**

- Introduced a “roost” (goal point) that birds remember.
- Each bird:

  - Tries to return to the closest point it ever was to the roost (personal best).
  - Shares its best with others (global best).

- Insight: Replace the “roost” with a **fitness function** → use this to solve optimization problems.

---

## **What is Particle Swarm Optimization (PSO)?**

PSO is a population-based optimization technique. It tries to find the minimum (or maximum) of a function (e.g., minimize error).

### **Core Idea**:

- Multiple **particles** (candidate solutions) explore the search space.
- Each particle:

  - Has a **position** and a **velocity**.
  - Remembers its **personal best** position.
  - Knows the **global best** position found by any particle.
  - Moves based on a mix of its own best and the global best.

---

## **The Canonical PSO Algorithm**

### **Definitions**:

For each particle $i$:

- $x_i$: current position
- $v_i$: current velocity
- $pb_i$: personal best position
- $gb$: global best position
- $f(x_i)$: fitness value at current position

### **Algorithm Steps**:

1. Initialize particles with random positions and velocities.
2. Repeat until stopping criteria met:

   - For each particle:

     - Evaluate fitness.
     - If current fitness is better than personal best, update $pb_i$.
     - If current fitness is better than global best, update $gb$.

   - Update velocities:

     $$
     v_i^{t+1} = v_i^t + \phi_1 U_1 (pb_i - x_i^t) + \phi_2 U_2 (gb - x_i^t)
     $$

     where:

     - $\phi_1, \phi_2$: constants controlling influence
     - $U_1, U_2$: random numbers between 0 and 1

   - Update positions:

     $$
     x_i^{t+1} = x_i^t + v_i^{t+1}
     $$

---

## **Explanation of Velocity Update**

### Three parts:

- **Momentum**: $v_i^t$ — keeps moving in the same direction.
- **Personal influence**: moves toward personal best.
- **Social influence**: moves toward global best.

Graphically, in 2D, the new direction is a mix of all three.

---

## **PSO in Action – Summary of Steps**

1. Initialize particles (positions and velocities).
2. Evaluate fitness of all particles.
3. Update each particle’s personal best.
4. Update the global best.
5. Compute new velocities based on:

   - Current velocity (momentum)
   - Pull toward personal best
   - Pull toward global best

6. Update positions.
7. Repeat from step 2 until done.

---

## **Extensions of PSO**

### **Population Topology**

- Using only global best can lead to premature convergence.
- **Alternative**: Use **local best** (best in a neighborhood).

  - Slows down convergence.
  - Increases exploration and chance of finding global optimum.

#### Velocity Update (Local best version):

$$
v_i^{t+1} = v_i^t + \phi_1 U_1 (pb_i - x_i^t) + \phi_2 U_2 (lb_i - x_i^t)
$$

### **Neighborhood Structures**:

- **Low connectivity**: slow info sharing → better exploration.
- **High connectivity**: fast info sharing → faster convergence, but risk of local optima.

---

## **Inertia / Momentum Weight**

Adds a weight $w$ to the momentum component:

$$
v_i^{t+1} = w v_i^t + \phi_1 U_1 (pb_i - x_i^t) + \phi_2 U_2 (gb - x_i^t)
$$

- $w$: inertia weight

  - High → more exploration (particles roam more)
  - Low → more exploitation (particles fine-tune)

- Often **decreased over time** to first explore, then exploit.

---

## **Other Variants of PSO**

- Dynamic neighborhood structures
- Enhanced diversity control
- Modified update rules
- PSO adapted to **discrete** problems
- Related to other methods like:

  - **Gradient-based optimization**
  - **Genetic algorithms**
  - **Reinforcement learning**

---

## **Summary**

**Particle Swarm Optimization (PSO)**:

- Inspired by natural flocking behavior.
- Uses a population of particles to explore the search space.
- Each particle adjusts based on its own and neighbors' experiences.
- Extensions include local best, inertia weight, and varied topologies.

---
