---
### üìò Multi-Agent Reinforcement Learning (MARL)
---

### üîç What is Multi-Agent Learning?

Multi-agent learning (MAL) studies systems where **two or more autonomous agents** interact and learn from experience. Unlike single-agent learning, where theoretical guarantees exist, these guarantees often break down when **multiple learners** are involved.

**Stone and Tuyls Definition**:

> "The study of multiagent systems in which one or more autonomous entities improve automatically through experience."

---

### üß† Background Concepts

#### üîÅ Reinforcement Learning (RL)

- A **key technique** for agents to adapt and learn from interacting with the environment.
- Single agent interacts with environment: chooses actions (A), receives rewards (R), transitions to new states (S).

#### üé≤ Classical Game Theory

- Focuses on **strategic decision making** among **rational players**.
- Assumes full information and rationality.
- Key concept: **Nash Equilibrium** ‚Äì a situation where no player can benefit by changing strategy while others keep theirs fixed.

#### üß¨ Evolutionary Game Theory (EGT)

- Inspired by biological evolution rather than rationality.
- Agents update strategies based on payoff (fitness), not necessarily rational decisions.

  Two key **replicator dynamic** equations:

  1. $$
     \frac{dp_i}{dt} = p_i(e_i^T A q - p^T A q)
     $$

     - $p_i$: proportion of population using strategy $i$
     - $e_i$: unit vector for strategy $i$
     - $A$: payoff matrix
     - $q$: opponent strategy

  2. $$
     \frac{dq_i}{dt} = q_i(p^T B e_i - q^T B p)
     $$

     - $q_i$: strategy distribution for opponent
     - $B$: opponent‚Äôs payoff matrix

---

### üö® The Multi-Agent Challenge

In a multi-agent setting:

- Agents no longer adapt in isolation.
- The environment becomes **non-stationary** due to others learning.
- Even **fully cooperative agents** may struggle due to communication costs or failures.
- **Markov property** often breaks down because agent actions depend on unknown actions of others.

---

### üåç Why Use Multi-Agent Systems?

Multi-agent systems are used in:

- **Teamwork**: sports, exploration robots, sensor networks
- **Scheduling**: job shops, traffic lights
- **Trading**: auctions, stock markets
- **Simulations**: military strategy, economic modelling

---

### üß© Learning Paradigms in Multi-Agent Systems

1. **Online RL toward individual utility**
2. **Online RL toward social welfare**
3. **Co-evolutionary learning**
4. **Swarm Intelligence**
5. **Adaptive mechanism design**

---

### üõ†Ô∏è Components of a Multi-Agent Learning System

1. **The Environment**

   - Defines state space, action space, and how states change (transition function).

2. **The Agents**

   - Can communicate with the environment and each other.
   - Have utility functions (preferences).
   - Use policies to choose actions.

3. **The Interaction Mechanism**

   - Specifies how and when agents interact.
   - Determines observability and whether interactions are simultaneous or sequential.

4. **The Learning Mechanism**

   - Defines:

     - Who learns (individual or group)
     - What is being learned (e.g., policies)
     - What data is available
     - How behaviour is updated (learning rule)
     - The learning objective (e.g., maximize reward)

---

### ‚öñÔ∏è Game Theory as a Framework

Game theory provides a structured way to model interactions:

- **Actions**: what each agent can do
- **Strategies**: probability distributions over actions
- **Joint actions**: determine outcomes (payoffs)
- If players are **rational** and have **full knowledge**, Nash equilibrium can predict behaviour.

---

### ü§ù Cooperation vs Competition

In real applications, agents may:

- Have **common goals** (e.g. robots cleaning a house together).
- Be **competitive** (e.g. buyers in an auction).
- Need to **coordinate** or **negotiate** (e.g. traffic flow).

This leads to questions like:

- What does "optimal" mean in multi-agent settings?
- How can agents learn to act optimally?

---

### ‚è≥ Historical Perspective

#### üìå Startup Phase (Late 1980s ‚Äì Early 2000s)

- Inspired by nature: ant colonies, herding, imitation.
- Exploratory and broad.
- Early MARL efforts began here.

#### üìå Consolidation Phase (2000s ‚Äì Now)

- Focus shifted to theoretical foundations.
- Game-theoretic RL became central.

---

### ‚úÖ Summary

- Multi-Agent Learning is fundamentally different from single-agent RL.
- Key questions:

  - What should agents learn (objectives)?
  - How should they learn (algorithms)?

- Multiple paradigms exist, depending on context.
- Game Theory and Evolutionary Game Theory provide useful tools and models.
- Practical applications are wide-ranging and highly impactful.

---
