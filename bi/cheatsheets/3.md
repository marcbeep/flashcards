## 1. Introduction to Probability

**Probability** is the mathematical study of uncertainty ‚Äî it describes how likely events are to happen.

- **Random Variable**:

  - A variable \( X \) that takes different values representing possible outcomes of a process.
  - We denote the probability of \( X \) taking value \( x \) as \( p(x) = \mathbb{P}(X = x) \).

- **Sample Space (\( \mathcal{S} \))**:

  - The set of all possible outcomes of an experiment.
  - Examples:
    - Tossing a coin once: \( \mathcal{S} = \{H, T\} \).
    - Tossing a coin twice: \( \mathcal{S} = \{HH, HT, TH, TT\} \).

- **Probability Mass Function (PMF) or Density Function (PDF)**:
  - **Discrete** case: PMF assigns probability \( p(x) \) to each outcome \( x \) (e.g., coin toss).
  - **Continuous** case: PDF assigns probability _density_ over intervals.

**Key Properties**:

- \( p(x) \geq 0 \) for all \( x \).
- \( \sum_x p(x) = 1 \) (for discrete), or \( \int p(x) dx = 1 \) (for continuous).

---

## 2. Basic Probability Concepts

### 2.1 Random Experiment

An action or process that leads to one of several outcomes, even under identical conditions.

Examples:

- Tossing a coin.
- Rolling a dice.
- Measuring rainfall.

---

## 3. Key Probability Rules

Understanding relationships between events is critical. These rules formalize how probabilities combine.

---

### 3.1 **Joint Probability**

- **Definition**: Probability that **two events happen together**.
- Example:

  - Probability that a randomly selected fruit is an **orange** from the **red basket**.

- **Mathematically**:  
  \[
  \mathbb{P}(X = x, Y = y)
  \]
  where \( X \) and \( Y \) are random variables.

**Illustration** (from the lecture example):
| | F = orange | F = apple | Total |
|---------|------------|-----------|-------|
| B = red | 30 | 10 | 40 |
| B = blue| 15 | 45 | 60 |
| Total | 45 | 55 | 100 |

Example:
\[
\mathbb{P}(B = r, F = o) = \frac{30}{100} = 0.3
\]

---

### 3.2 **Sum Rule** (Marginal Probability)

- **Definition**: To find the probability of an event regardless of another variable, **sum over** the other variable.

- **Formula**:
  \[
  \mathbb{P}(X = x) = \sum_y \mathbb{P}(X = x, Y = y)
  \]
- **Example**:
  - What is the probability of picking an orange? (regardless of basket)
    \[
    \mathbb{P}(F = o) = \frac{45}{100} = 0.45
    \]

---

### 3.3 **Conditional Probability**

- **Definition**: The probability that one event happens given that we know another event happened.

- **Formula**:
  \[
  \mathbb{P}(Y = y | X = x) = \frac{\mathbb{P}(X = x, Y = y)}{\mathbb{P}(X = x)}
  \]

- **Example**:
  - Probability that the basket is red given the fruit is orange:
    \[
    \mathbb{P}(B = r | F = o) = \frac{30}{45} = \frac{2}{3}
    \]

---

### 3.4 **Product Rule**

- **Definition**: Relates joint probability to conditional and marginal probability.

- **Formula**:
  \[
  \mathbb{P}(X = x, Y = y) = \mathbb{P}(Y = y | X = x) \mathbb{P}(X = x)
  \]

- **Example**:
  - We can calculate the joint probability if we know conditional and marginal probabilities.

---

### 3.5 **Bayes‚Äô Rule**

- **Definition**: A way to "invert" conditional probabilities.
- **Motivation**: Given \( \mathbb{P}(B|A) \) and \( \mathbb{P}(A) \), how can we find \( \mathbb{P}(A|B) \)?

- **Formula**:
  \[
  \mathbb{P}(A|B) = \frac{\mathbb{P}(B|A) \mathbb{P}(A)}{\mathbb{P}(B)}
  \]

**Where**:

- \( \mathbb{P}(A) \) = prior probability (belief before evidence)
- \( \mathbb{P}(B|A) \) = likelihood (how likely evidence is under assumption)
- \( \mathbb{P}(B) \) = marginal probability of evidence
- \( \mathbb{P}(A|B) \) = posterior probability (updated belief after evidence)

**Intuition**:

- We update our belief about \( A \) after observing \( B \).

---

## üçä Problem Setup (from the lecture):

We have two baskets:

- **Red Basket (R)**: 6 oranges, 2 apples
- **Blue Basket (B)**: 1 orange, 3 apples
- Total fruits in Red: 8
- Total fruits in Blue: 4

Also:

- Probability of choosing **Red Basket**: \( P(R) = 0.4 \)
- Probability of choosing **Blue Basket**: \( P(B) = 0.6 \)

---

## ‚ùì Question:

**If I pick a fruit and it‚Äôs an orange, what is the probability that it came from the red basket?**

That‚Äôs:
\[
P(R \mid O) = ?
\]

We are trying to **reverse** the probability:

- We know \( P(O \mid R) \) ‚Äî the chance of orange **if red basket is chosen**
- We want \( P(R \mid O) \) ‚Äî the chance it was red **given that we saw an orange**

---

## ‚úÖ Step-by-Step with Bayes' Rule:

### Step 1: Write Bayes' Rule

\[
P(R \mid O) = \frac{P(O \mid R) \cdot P(R)}{P(O)}
\]

---

### Step 2: Find the individual terms

1. **Likelihood**:  
   Probability of orange if we picked the red basket:
   \[
   P(O \mid R) = \frac{6}{8} = 0.75
   \]

2. **Prior**:  
   Probability of choosing red basket:
   \[
   P(R) = 0.4
   \]

3. **Marginal (total) probability of orange**:  
   Use total probability:
   \[
   P(O) = P(O \mid R) \cdot P(R) + P(O \mid B) \cdot P(B)
   \]
   Where:
   \[
   P(O \mid B) = \frac{1}{4} = 0.25,\quad P(B) = 0.6
   \]
   So:
   \[
   P(O) = (0.75 \cdot 0.4) + (0.25 \cdot 0.6) = 0.3 + 0.15 = 0.45
   \]

---

### Step 3: Plug into Bayes' Rule

\[
P(R \mid O) = \frac{0.75 \cdot 0.4}{0.45} = \frac{0.3}{0.45} = \frac{2}{3}
\]

---

## üéâ Final Answer:

\[
\boxed{P(R \mid O) = \frac{2}{3}}
\]

So, **if you picked an orange**, there‚Äôs a **2 in 3 chance** it came from the **red basket**.

---
