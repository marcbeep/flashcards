---

## 🔍 Convolution Layer

### 📐 Basic Concept

A convolution layer processes input images using **filters** (small grids of numbers) that slide across the image to detect patterns (like edges or textures).

### 🧮 Convolution Operation

Given:

- An image (e.g., 32x32x3: height, width, and depth for RGB)
- A filter (e.g., 5x5x3)

The operation:

- The filter slides over the image spatially.
- At each step, it performs a **dot product** between the filter and the corresponding image patch.
- The result is one number per position (called an **activation**).

Formula:

$$
\text{Activation} = w^T x + b
$$

Where:

- $w$ = filter weights (flattened into a vector)
- $x$ = image patch (also flattened)
- $b$ = bias term

---

### ➕ Padding

To keep output size the same as input:

- Use **zero-padding**, i.e., add zeros around the border.
- Padding size = (Filter size - 1)/2
  e.g., for 3x3 filter → pad with 1 pixel

---

### 🚶 Stride

Stride = how many pixels the filter moves each time.

**Output size** (1D formula):

$$
\text{Output size} = \frac{N - F}{S} + 1
$$

Where:

- $N$ = input size
- $F$ = filter size
- $S$ = stride

---

## 🧱 Structure of a Convolution Layer

### Example:

- Input: 32x32x3 (RGB image)
- Filter: 5x5x3
- Result: 28x28 activation map (if no padding and stride = 1)

Using multiple filters:

- 6 filters → 6 activation maps → stacked to form 28x28x6 output

### With Padding:

- If padding = 2 and stride = 1, then:

  $$
  \frac{32 + 2\times2 - 5}{1} + 1 = 32
  $$

  → Output: 32x32x6

---

## 🔧 Hyperparameters in Convolution Layer

You need to set:

| Parameter | Description                       |
| --------- | --------------------------------- |
| K         | Number of filters → affects depth |
| F         | Filter size (FxF)                 |
| S         | Stride (how much filter moves)    |
| P         | Padding (zero padding size)       |

**Output volume size:**

- Width: $(W1 - F + 2P)/S + 1$
- Height: $(H1 - F + 2P)/S + 1$
- Depth: = K (number of filters)

---

## 🤖 ConvNet (Convolutional Neural Network)

### What is a ConvNet?

A deep learning model that:

- Applies multiple **convolution layers**
- Uses **activation functions** like ReLU
- Optionally includes **pooling** and **fully connected** layers

### Example Stack:

1. Conv (6 filters of 5x5x3) + ReLU → 28x28x6
2. Conv (10 filters of 5x5x6) + ReLU → 24x24x10
3. Repeat...

---

## 👁️ Visualization

- Zeiler & Fergus (ECCV 2014): showed that different filters detect different features like edges, textures, or object parts.

---

## 📉 Pooling Layer

### Purpose:

- Reduces spatial size (height/width), not depth
- Helps make features more manageable and less sensitive to exact position

### 🏊 Types:

- **Max Pooling**: selects the maximum value in each region
- Applied **independently per activation map**

### 🔧 Hyperparameters:

- Filter size (F)
- Stride (S)

**Output size formula:**

$$
\text{Output width} = \frac{W1 - F}{S} + 1 \\
\text{Output height} = \frac{H1 - F}{S} + 1 \\
\text{Depth remains unchanged}
$$

**Common settings:**

- F = 2, S = 2 (halves spatial dimensions)
- F = 3, S = 2

> Zero-padding is rarely used in pooling.

---

## 🧠 Fully Connected (FC) Layer

### Purpose:

- Final decision-making stage (e.g., classification)
- Connects every neuron from the previous layer to each neuron in this layer

### Example:

- Input volume: 32x32x3 = 3072 values
- Flattened to a vector
- Weight matrix: e.g., 10x3072 for 10 output classes
- Output: 10x1 (one value per class)

---
