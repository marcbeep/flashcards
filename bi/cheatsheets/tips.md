# COMP532-Machine-Learning-and-Bioinspired-Optimisation

Key Knowledge Points for Machine Learning and Bioinspired Optimisation Exam

- 25MCQs
- 3/4 written questions

## 1. Reinforcement Learning (RL) Basics:

- Understand the distinction between **on-policy** and **off-policy** learning. On-policy methods update the policy based on actions taken under the current policy, whereas off-policy methods learn from data generated by any policy.
- Learn about **Q-learning** and its bootstrapping mechanism, which updates Q-values based on estimated future rewards without waiting for the completion of the episode.
- **Eligibility traces** and **Temporal Difference (TD) learning** are techniques used in RL to efficiently update values based on partial information.
- The **Bellman equation** is central in reinforcement learning. Understand both the optimality equation and how the equation changes under a given policy.

## 2. Deep Learning and Neural Networks:

- Be familiar with **activation functions** such as **ReLU**, **sigmoid**, and **hyperbolic tangent**. Focus on how **ReLU** helps mitigate the **vanishing gradient problem** by allowing for non-zero gradients in deep networks.
- **Overfitting** in neural networks can be addressed with techniques like **dropout** and **early stopping**, which prevent the model from becoming too complex and overfitting to the training data.
- **Backpropagation** is the fundamental algorithm for training neural networks. Be prepared to explain the flow of error gradients backward through the network to update weights.
- Understand **gradient descent** and its variants like **momentum** for optimization in neural networks. Learn how the **learning rate** controls the size of weight updates during training.

## 3. Evolutionary Algorithms and Swarm Intelligence:

- Study **genetic algorithms** and **evolutionary strategies**. Understand how **mutation** and **crossover** operators work to explore new areas of the solution space and improve the population over generations.
- **Swarm Intelligence** algorithms like **Ant Colony Optimization (ACO)** and **Particle Swarm Optimization (PSO)** are inspired by natural systems such as ant colonies and bird flocking. Learn the basic principles behind these algorithms, such as pheromone updating in ACO and velocity updates in PSO.

## 4. Optimization and Game Theory:

- **Zero-Sum Games** are games where one player's gain is another player's loss. Understand how these games are modeled and how **Nash Equilibrium** represents stable strategies where no player benefits from unilaterally changing their strategy.
- **Normal-Form Games** are represented by payoff matrices, where players choose strategies simultaneously. Familiarize yourself with how to compute and interpret equilibrium strategies.

## 5. Multi-Armed Bandit and Exploration Strategies:

- The **\(\epsilon\)-greedy algorithm** is a classic strategy for balancing exploration and exploitation in multi-armed bandit problems. Learn how this algorithm uses a small probability \(\epsilon\) to randomly explore new actions, while exploiting the best-known option with probability \(1 - \epsilon\).
- **Q-learning** is an off-policy RL algorithm that can learn optimal actions in unknown environments. Understand how **exploration** in Q-learning is handled using **epsilon-greedy** or other exploration techniques like **softmax**.

## 6. Bioinspired Optimization:

- **Bioinspired optimization** methods mimic natural processes to find solutions to complex problems. Review the most common algorithms, such as **Ant Colony Optimization** (ACO), **Particle Swarm Optimization** (PSO), and **Genetic Algorithms**, and how they can be applied to various optimization tasks.

## 7. Convolutional and Recurrent Neural Networks:

- **Convolutional Neural Networks (CNNs)** are powerful tools for image recognition and other tasks that involve grid-like data. Understand how convolutional layers work to extract hierarchical features and how these features help in classification tasks.
- **Recurrent Neural Networks (RNNs)** are crucial for sequence data, like time series or text. Be prepared to discuss how **LSTM units** address the vanishing gradient problem in RNNs.

## 8. Exam Preparation Tips:

- Focus on understanding **concepts and definitions**. Being able to explain the theory behind algorithms and their applications is crucial.
- Practice **derivations** and **equations**. Ensure that you can derive key equations like the **Bellman equation** or the **gradient update rule** for neural networks.
- **Work through examples** of algorithms like **Q-learning**, **Ant Colony Optimization**, and **Neural Networks** to gain a deeper understanding.
- Remember the balance between **exploration** and **exploitation** in reinforcement learning and how different algorithms address this challenge.

By mastering these topics, you'll be well-prepared to tackle the exam. Good luck!
