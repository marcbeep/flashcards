---

### ðŸ§¬ Evolutionary Game Theory (EGT)

- **Classic Game Theory**: Based on economic principles. Players are rational and aim to maximize payoffs. The key idea is **Nash Equilibrium**, where no player benefits from changing strategy alone.
- **Evolutionary Game Theory**: Inspired by biology. Players (individuals) are not necessarily rational but evolve over time through **selection** (rewards) and **mutation** (random change).

  - Focuses on **populations** where strategies (or types) compete.
  - Central concepts:

    - **Replicator Dynamics**
    - **Evolutionarily Stable Strategies (ESS)**

---

### ðŸ”„ The Prisonerâ€™s Dilemma in EGT

- Payoff Matrix:

  |       | C   | D   |
  | ----- | --- | --- |
  | **C** | 3,3 | 0,5 |
  | **D** | 5,0 | 1,1 |

- In EGT, the population includes:

  - **Cooperators (C)**
  - **Defectors (D)**

- Fitness (reproductive success) depends on interactions.

- If equal numbers of C and D:

  - **Câ€™s average fitness** = (3 + 0)/2 = 1.5
  - **Dâ€™s average fitness** = (5 + 1)/2 = 3
  - â†’ Defectors increase in the population.

---

### ðŸ“ˆ Replicator Dynamics (Single Population)

Explains how the proportion of each type (strategy) changes over time.

**Formula**:

$$
\dot{x_i} = x_i (f_i(x) - \bar{f}(x))
$$

Where:

- $x_i$: fraction of population playing strategy $i$
- $f_i(x)$: fitness of strategy $i$
- $\bar{f}(x)$: average fitness of the population

**Meaning**: If a strategy does better than average, it grows; if worse, it shrinks.

Applied to Prisoner's Dilemma:

$$
\dot{x} = x^\top A x - x^\top A x
$$

- Where $x$ is a vector of proportions and $A$ is the payoff matrix.

- **Fixed Points**:

  - All **Defectors** (x = 0): Stable
  - All **Cooperators** (x = 1): Unstable

---

### âœŒï¸ Rock-Paper-Scissors Example

Payoff matrix:

$$
A =
\begin{bmatrix}
0 & -1 & 1 \\
1 & 0 & -1 \\
-1 & 1 & 0
\end{bmatrix}
$$

- Mixed Nash Equilibrium at $(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$
- No strategy wins long term â€” dynamics cycle endlessly.

---

### ðŸ‘¥ Multi-Population Replicator Dynamics

Used when **two players or groups** interact.

Formulas:

$$
\dot{x_i} = x_i ((A y)_i - x^\top A y)
$$

$$
\dot{y_i} = y_i ((x^\top B)_i - x^\top B y)
$$

Where:

- $x, y$: distributions in each population
- $A, B$: payoff matrices for each player

Each population evolves **independently**, but their fitness depends on the other.

---

### ðŸ”ƒ Examples of Multi-Agent Dynamics

Visual simulations show strategy evolution for:

- **Prisonerâ€™s Dilemma**: Defection dominates.
- **Stag Hunt**: Two stable strategies (coordination game).
- **Matching Pennies**: Cycles; no stable equilibrium.

---

### ðŸ”— Connection to Reinforcement Learning

- **Cross Learning** (a simple learning rule for agents) has been shown to converge to replicator dynamics in the continuous time limit.
- This creates a formal link between **multi-agent reinforcement learning** and **evolutionary game theory**.

---

### ðŸ“˜ Dictionary Comparison

| Reinforcement Learning | Classical Game Theory | Evolutionary Game Theory |
| ---------------------- | --------------------- | ------------------------ |
| environment            | game                  | game                     |
| agent                  | player                | population               |
| action                 | action                | type                     |
| policy                 | strategy              | distribution over types  |
| reward                 | payoff                | fitness                  |

---

### ðŸ›¡ï¸ Evolutionarily Stable Strategies (ESS)

- A strategy $x$ is **ESS** if:

  1. $u(x, x) \ge u(y, x)$ for all $y$
  2. If $u(x, x) = u(y, x)$, then $u(x, y) > u(y, y)$

Where $u(a, b)$ is the payoff when strategy $a$ meets $b$.

In Prisoner's Dilemma:

- Defection is an ESS because it performs better against any mix of strategies.

---

### ðŸ”€ Selection-Mutation Dynamics

Adds **mutation** to the replicator dynamics.

Formula:

$$
\dot{x_i} = x_i(f_i(x) - \bar{f}(x)) + \sum_{j \ne i} [\mu_{ji} x_j - \mu_{ij} x_i]
$$

Where:

- $\mu_{ji}$: mutation rate from $j$ to $i$

This allows diversity in strategies and avoids getting stuck in pure strategies.

---

### ðŸ”š Final Note

Replicator dynamics are more than just theoretical tools â€” they help us understand how learning works in **multi-agent reinforcement learning** systems, especially when agents are not fully rational or informed.

---
