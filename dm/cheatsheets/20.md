---
### **Agglomerative Clustering: Overview**

Agglomerative clustering is a **bottom-up** hierarchical clustering method. It starts with each object in its **own cluster** and **merges** them step by step into larger clusters.
---

### **Algorithm Steps**

Given a dataset **ùíü**:

1. **Initialize**: Each object is its own cluster.
2. **Repeat**:

   - Find the **closest pair** of clusters, say **i** and **j**.
   - **Merge** them into a new cluster.

3. **Stop** when a **termination criterion** is met (e.g. desired number of clusters).
4. **Output**: A clustering, a hierarchy (dendrogram), or a set of nested clusterings.

---

### **Key Concept: Proximity Between Clusters**

To decide which clusters to merge, we need a way to **measure distance (proximity)** between clusters. Different strategies lead to different results.

---

### **Linkage Methods (Ways to Measure Distance Between Clusters)**

#### 1. **Single-Linkage (Nearest Neighbor)**

- Distance between two clusters = **minimum distance** between any two points, one from each cluster.
- Formula:

  $$
  \text{dist}(P, Q) = \min_{X \in P, Y \in Q} d(X, Y)
  $$

- This can create long, chain-like clusters.

#### 2. **Complete-Linkage (Furthest Neighbor)**

- Distance between two clusters = **maximum distance** between any two points, one from each cluster.
- Formula:

  $$
  \text{dist}(P, Q) = \max_{X \in P, Y \in Q} d(X, Y)
  $$

- Tends to create **compact, spherical** clusters by trying to keep the diameter (largest distance within a cluster) small.

#### 3. **Group-Average Linkage**

- Distance = **average distance** between all pairs of points (one from each cluster).
- Let:

  - **p** = number of points in cluster P
  - **q** = number of points in cluster Q

- Formula:

  $$
  \text{dist}(P, Q) = \frac{1}{p \cdot q} \sum_{X \in P, Y \in Q} d(X, Y)
  $$

- Balances between single- and complete-linkage methods.

---
