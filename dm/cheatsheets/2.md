# üìö **Data Preprocessing & Model Performance Study Sheet**

---

## **1. Missing Values**

### üîç **Problem**

Some feature values are unknown or not recorded in the dataset.

### ‚öôÔ∏è **Handling Strategies**

| Method                    | Description                     | Pros                  | Cons                           |
| ------------------------- | ------------------------------- | --------------------- | ------------------------------ |
| **1. Discard**            | Remove rows with missing values | Simple                | Loss of useful data            |
| **2. Fill by Hand**       | Manually re-measure or annotate | Accurate              | Time-consuming, costly         |
| **3. Set "missingValue"** | Use a constant like `"missing"` | Useful for categories | Misleading for numbers         |
| **4. Replace with Mean**  | Use feature‚Äôs average value     | Easy, quick           | Inaccurate if outliers present |
| **5. Predict Missing**    | Train model to fill gaps        | Can be accurate       | Adds complexity                |
| **6. Accept Missing**     | Let algorithm handle it         | No extra work         | Risk if missing values are key |

---

## **2. Noisy Data**

### üîç **Problem**

Random errors or corruption in data can lead to **overfitting** and inaccurate models.

### ‚öôÔ∏è **Detection Techniques**

- Obvious errors: wrong data types, extreme outliers
- Subtle errors: typos like `0.52` instead of `0.25`

### üõ†Ô∏è **Handling Strategies**

| Method                  | Description                         | Best For              |
| ----------------------- | ----------------------------------- | --------------------- |
| **Manual Inspection**   | Remove by hand                      | Small datasets        |
| **Clustering**          | Remove outliers based on groups     | High-dimensional data |
| **Linear Regression**   | Remove values far from trend line   | Numerical data        |
| **Frequency Threshold** | Drop rare values                    | Text/misspellings     |
| **Treat as Missing**    | Then apply missing value techniques | Seamless integration  |

---

## **3. Overfitting vs. Underfitting**

### ‚öñÔ∏è **Definitions**

| Term             | Description                            | Symptoms                               |
| ---------------- | -------------------------------------- | -------------------------------------- |
| **Overfitting**  | Model too complex, fits training noise | High train accuracy, low test accuracy |
| **Underfitting** | Model too simple, misses patterns      | Low train & test accuracy              |

---

### üõ†Ô∏è **Solutions**

| Problem          | Fix                                                                                          |
| ---------------- | -------------------------------------------------------------------------------------------- |
| **Underfitting** | More training, better features, cleaner data, try better algorithm                           |
| **Overfitting**  | Simplify model, regularization, remove features, early stopping, more data, cross-validation |

---

## **4. Feature Normalisation**

### üìè **Purpose**

Scale features to a common range so no single feature dominates due to scale.

### üßÆ **Methods**

| Method                     | Formula                                                               | Output Scale  | When to Use                           |
| -------------------------- | --------------------------------------------------------------------- | ------------- | ------------------------------------- |
| **[0,1]-Scaling**          | \(\hat{x} = \frac{x - \text{min}(x)}{\text{max}(x) - \text{min}(x)}\) | [0,1]         | Neural networks, bounded-input models |
| **Gaussian Normalisation** | \(\hat{x} = \frac{x - \mu}{\sigma}\)                                  | Mean 0, Std 1 | Linear models, distance-based methods |

---

‚úÖ **Quick Tips**

- Always check for **missing or noisy data** before training.
- Normalize **numerical features** if algorithms are sensitive to scale.
- Monitor for **overfitting** using validation/test performance.
- Use **cross-validation** to detect and prevent model bias.
