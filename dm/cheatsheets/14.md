---

## k-Means Algorithm

### Overview

k-Means is a **representative-based clustering algorithm** used to partition data into **k clusters**. The goal is to find **k representative points (centroids)** such that the **sum of distances between each data point and its closest representative is minimized**.

Let:

- **k** = number of clusters
- **D = {X₁, X₂, ..., Xₙ}** = dataset of n points
- **Y₁, ..., Yₖ** = cluster representatives (centroids)

The **objective function** to minimize is:

$$
\sum_{i=1}^{n} \min_{j} d(X_i, Y_j)
$$

This is the total distance from each point to the nearest representative.

### Representative-Based Algorithms

To define a specific algorithm, we need to specify:

1. **How to choose representatives** (e.g., random initialization)
2. **The distance function** (e.g., Euclidean)

Note: Representatives **do not need to be actual data points**.

---

## General k-Representatives Approach

1. **Initialise**: Pick initial k representatives
2. **Iteratively refine**:

   - **Assign step**: Assign each data point to the **nearest representative** using the distance function
     → This creates clusters **C₁, ..., Cₖ**
   - **Optimise step**: For each cluster Cⱼ, update its representative Yⱼ to **minimize local distances**

$$
\sum_{X_i \in C_j} d(X_i, Y_j)
$$

---

## k-Means Specifics

- Uses **squared Euclidean distance**:

  $$
  \|X - Y\|^2 = (X₁ - Y₁)^2 + (X₂ - Y₂)^2 + ...
  $$

- Goal: **Minimize total within-cluster sum of squares (WCSS)**:

  $$
  \sum_{j=1}^{k} \sum_{X \in C_j} \|X - Y_j\|^2
  $$

- The optimal representative (Yⱼ) for each cluster is the **mean (centroid)** of its points:

  $$
  Y_j = \frac{1}{|C_j|} \sum_{X \in C_j} X
  $$

---

## k-Means Algorithm (Step-by-Step)

Given:

- Dataset D = {X₁, ..., Xₙ}
- Number of clusters k

### Steps:

1. **Initialisation Phase**:

   - Randomly select k representatives Y₁, ..., Yₖ

2. **Assignment Phase**:

   - Assign each data point to the **closest representative** (based on squared Euclidean distance)
   - Forms clusters C₁, ..., Cₖ

3. **Optimisation Phase**:

   - Update each representative Yⱼ to be the **mean of points in cluster Cⱼ**

Repeat Steps 2 and 3 until convergence:

- No data points change clusters
- OR a fixed number of iterations is reached

---

## Issues with k-Means

- **Random initialisation** can lead to **different results** (local minima)
- **Sensitive to outliers**: outliers can heavily shift the mean
- **Means are not actual data points**
- **Euclidean distance** is not suitable for **categorical features**
- **No spatial awareness**: pixel location isn't considered in image segmentation

Tip: Run k-Means **multiple times with different initialisations**, choose the run with the **lowest WCSS**.

---

## Example: Image Segmentation

- Goal: Group similar pixels in an image
- Each **pixel is a point in 3D RGB space**
- Use k-Means to cluster pixels into **k color clusters**
- Result: image segmented into k regions of similar color
- **Note**: Ignores pixel location, purely based on color similarity

---
