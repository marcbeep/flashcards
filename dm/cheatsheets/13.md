---

## Clustering Evaluation

Clustering quality is evaluated using two main types of methods:

### 1. **Extrinsic Methods (Supervised)**

- Use ground truth labels (i.e., known class labels for data).
- Measure how well the clustering output aligns with the known labels.
- Treat clustering as a classification task.

#### Basic Steps:

1. Assign each cluster the label that appears most frequently in it.
2. Merge clusters that are given the same label.
3. For each label (class), compute:

   - **Precision** = Correctly clustered items / Total items in cluster
   - **Recall** = Correctly clustered items / Total items with that label
   - **F1-score** = Harmonic mean of precision and recall.

4. Compute the **macro-average**: average these metrics across all labels.

---

#### **B-CUBED Evaluation Measure**

A widely used extrinsic evaluation method for clustering.

**Definitions**:

- Let **C(x)** = Cluster to which item **x** belongs.
- Let **A(x)** = Actual class/label of item **x**.

**For each item x**:

- **Precision(x)** = Number of items in C(x) that have A(x) / Total items in C(x)
- **Recall(x)** = Number of items in C(x) that have A(x) / Total items with label A(x)

**Overall Metrics**:

- **Average Precision** = Sum of precision(x) for all x / N
- **Average Recall** = Sum of recall(x) for all x / N
- **Average F1-score** = Sum of F(x) for all x / N

Where:

- **F(x)** = (2 × Precision(x) × Recall(x)) / (Precision(x) + Recall(x))
- N = Total number of items in the dataset

---

#### Example: **Community Mining**

Task: Cluster 50 personal names from 5 domains (e.g. actors, politicians) using semantic similarity measures.

**Method**:

- Used **group-average agglomerative hierarchical clustering (GAAC)**.
- Merged clusters based on correlation defined as:

  $$
  \text{Corr}(Θ) = \frac{1}{2} \cdot \frac{1}{|Θ|(|Θ|-1)} \sum_{(u,v)∈Θ} sim(u,v)
  $$

  - Θ: the merged cluster (from clusters A and B)
  - |Θ|: number of items in Θ
  - sim(u,v): similarity between items u and v

**Evaluation**:

- B-CUBED metric applied.
- Best-performing method (proposed) had highest F1 score: **0.7897**.

| Method     | Precision | Recall | F1 Score |
| ---------- | --------- | ------ | -------- |
| Proposed   | 0.7958    | 0.804  | 0.7897   |
| Sahami     | 0.6384    | 0.668  | 0.6426   |
| WebJaccard | 0.5926    | 0.712  | 0.6147   |
| WebDice    | 0.5895    | 0.716  | 0.6179   |
| WebOverlap | 0.5976    | 0.680  | 0.5965   |
| WebPMI     | 0.2649    | 0.428  | 0.2916   |
| Chen       | 0.4763    | 0.624  | 0.4984   |

---

### 2. **Intrinsic Methods (Unsupervised)**

- Do not use ground truth labels.
- Evaluate the quality of clusters based on internal properties like cohesion and separation.

#### **Silhouette Coefficient**

A widely used intrinsic method.

**For a data point x**:

- Let **a(x)** = Average distance from x to all other points in its own cluster.
- Let **b(x)** = Average distance from x to all points in the next nearest cluster.

Then,

$$
s(x) = \frac{b(x) - a(x)}{\max(a(x), b(x))}
$$

- If cluster has only one point (|C| = 1), then s(x) = 0.
- s(x) ∈ \[-1, 1]

**Interpretation**:

- **s(x) ≈ 1** → x is well clustered.
- **s(x) ≈ 0** → x is on the border of two clusters.
- **s(x) ≈ -1** → x may be in the wrong cluster.

**Overall Silhouette Score** = Average of s(x) over all x in the dataset.

---
