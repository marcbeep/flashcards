---

## **PageRank Algorithm – Explained Simply**

### **1. Web Surfing as a Markov Chain**

- Think of the web as a graph: each **webpage is a node** (or "state"), and each **hyperlink is a connection** (or "transition") between nodes.
- A **random web surfer** clicks on links at random — they don’t use the back button or type new URLs.
- At each page, they choose **one of the available links with equal probability**.

### **2. Transition Matrix (A)**

- This is a square matrix that shows the probability of moving from one page to another.
- If page `i` has `Oi` out-links (links to other pages), then the chance of moving from `i` to page `j` is:

  - `A[i][j] = 1/Oi` if there's a link from `i` to `j`
  - `A[i][j] = 0` if there's no link from `i` to `j`

### **3. Initial Probability Vector (P₀)**

- Represents the chance that a surfer starts on each page.
- Usually initialized with equal probability: e.g., for `n` pages, each page gets `1/n`.

### **4. Iterative Update of PageRank**

At each step, we calculate the new probability distribution `P₁` like this:

```
P₁ = Aᵀ * P₀
```

This means:

- Transpose the transition matrix `A`
- Multiply it by the current probability vector

Do this repeatedly:

```
P₂ = Aᵀ * P₁
...

Pₖ = Aᵀ \* Pₖ₋₁

```

### **5. Stationary Distribution**

- Eventually, the vector stops changing much — it **converges** to a steady-state `Π`.
- This `Π` is the **PageRank vector**: it tells you the long-term probability of ending up on each page.
- Mathematically:

```

Π = Aᵀ \* Π

```

So `Π` is the **principal eigenvector** of the matrix `Aᵀ` with eigenvalue 1.

---

## **Making the Matrix Work for the Real Web**

Real web graphs don’t satisfy the needed conditions for convergence (stochastic, irreducible, aperiodic). So, we **fix the matrix** in two ways:

### **Modification I: Handle Dangling Pages**

- **Dangling pages** have no out-links.
- Fix: Add a link from dangling pages to **every page**, each with equal probability `1/n`.

### **Modification II: Ensure Irreducibility and Aperiodicity**

- Add **a small chance** that the surfer jumps to any page from any page.
- Use a **damping factor** `d` (usually `0.85`) to control this.
- Modified matrix:

```

M = (1 − d)/n _ E + d _ Aᵀ

````

- `E` is a matrix of all 1s
- `(1 − d)/n` means there's always some chance to jump anywhere
- `d * Aᵀ` is the original behavior scaled down

---

## **Power Iteration Algorithm (How PageRank is Computed)**

Given:

- A graph `G` with `n` pages and no dangling vertices
- Damping factor `d` (typically 0.85)
- Tolerance `ε` (small number to stop when change is small)

### **Steps**

1. Initialize `P₀(i) = 1/n` for all pages `i`
2. Repeat:

 - For each page `i`, update:

   ```
   Pₖ(i) = (1 − d)/n + d * Σ [Pₖ₋₁(x)/Oₓ] over all (x → i)
   ```

   - `Oₓ` is the number of out-links from page `x`

3. Stop when `|Pₖ − Pₖ₋₁| ≤ ε` (i.e., small change)
4. Return `Pₖ` — the final PageRank vector

---

## **Additional Notes**

- PageRank doesn’t only apply to the web — it can rank any set of nodes in a graph.
- The algorithm is based on **random walks**, a powerful idea in graph theory.
- Often, we stop early (e.g., after a set number of steps), especially if only **relative ranking** is needed.
- In practice, convergence happens fast. Example: \~52 iterations on 322 million links.

---
````
