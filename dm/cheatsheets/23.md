---

### **Frequent Itemset and Association Rule Generation Framework**

Association rule mining happens in two main steps:

#### **Phase 1: Frequent Itemset Generation**

We try to find **all sets of items** (called **itemsets**) that occur **frequently** in a dataset, based on a **minimum frequency threshold (f)**.

Two methods:

- **Brute Force Algorithm**
- **Apriori Algorithm** (covered separately, not part of this file)

#### **Phase 2: Rule Generation**

From the frequent itemsets, generate **association rules** that meet a **minimum confidence threshold (c)**.

For each frequent itemset `I`:

- Generate **all pairs of subsets (X, Y)** such that:

  - `X âˆª Y = I`
  - `X` and `Y` are disjoint (donâ€™t overlap)

- For each rule `X â‡’ Y`, compute **confidence**:

  - If `confidence â‰¥ c`, store the rule.

---

### **Brute Force Algorithm**

#### **Key Concepts**

- Let `U` be the **set of all items**.
- The number of possible **non-empty itemsets** is `2^|U| - 1`.

Every one of these is a **candidate** for being frequent.

#### **Basic Brute Force Algorithm**

Input:

- `U`: the universe of items
- `ð’Ÿ`: the dataset (a list of transactions)
- `f`: frequency threshold

Steps:

1. For **every non-empty subset `I` of `U`**:
2. Compute **support** of `I`:

   - Support means **how many transactions contain `I`**.

3. If `support(I) â‰¥ f`, then `I` is **frequent**, so add it to the list.

âœ… **Problem:** If `|U| = 1000`, then the number of subsets = `2^1000`, which is more than `10^300` â€” too large to handle!

---

### **Downward Closure Property**

Very important for improving performance.

**Key idea:**

> If an itemset is frequent, then **all its subsets are also frequent**.

Therefore:

- If a certain size of itemset is **not frequent**, then **larger itemsets** containing it also **canâ€™t be frequent**.
- This helps us **prune the search space** and avoid unnecessary checks.

---

### **Improved Brute Force Algorithm**

This version uses the **Downward Closure Property**.

Steps:

1. For `k` from 1 to `|U|` (i.e. increasing itemset sizes):
2. For each **k-itemset** `I`:

   - Compute support of `I`
   - If `support(I) â‰¥ f`, then `I` is frequent

3. If **no k-itemsets** are frequent at any step, **stop** early (no point going further).

#### **Why itâ€™s better:**

- For **sparse datasets** (each transaction has only a few items), this method is much faster.
- If the largest transaction contains `l` items, then the total number of candidate itemsets is:

  - ![Formula](https://latex.codecogs.com/png.image?\dpi{110}\sum_{i=1}^l%20\binom{|U|}{i})
  - Much smaller than `2^|U|` when `l << |U|`.

**Example:**

- `|U| = 1000`, `l = 10`
- Then only need to consider roughly `1023` subsets instead of `10^300` â€” a huge improvement.

---

### **Summary**

- **Brute Force** checks **all item combinations**, which is simple but very slow for large `U`.
- The **Improved Brute Force** algorithm uses the **downward closure** trick to cut out many combinations early.
- Still, even improved methods struggle if the dataset has long transactions or low thresholds.
