[
  {
    "q": "Compute the Jaccard Index between the sentences:\nA: \"deep learning is fun and powerful\"\nB: \"machine learning is powerful and fun\"",
    "a": "- A = {deep, learning, is, fun, and, powerful}\n- B = {machine, learning, is, powerful, and, fun}\n\nIntersection = {learning, is, powerful, and, fun} → 5 items\nUnion = {deep, learning, is, fun, and, powerful, machine} → 7 items\n\nJaccard Index = 5 / 7 = \\mathbf{0.714}"
  },
  {
    "q": "Given vectors:\nX = (3, -2, 1), Y = (1, 4, -1)\nCompute the dot product X^T Y",
    "a": "\\[ 3*1 + (-2)*4 + 1*(-1) = 3 - 8 - 1 = \\mathbf{-6} \\]"
  },
  {
    "q": "Find the Euclidean distance between:\nX = (-1, 2, 2) and Y = (2, 0, 3)",
    "a": "\\[ \\sqrt{(2 + 1)^2 + (0 - 2)^2 + (3 - 2)^2} = \\sqrt{9 + 4 + 1} = \\sqrt{14} \\approx \\mathbf{3.74} \\]"
  },
  {
    "q": "Given matrix:\n\\[ A = \\begin{pmatrix} 2 & 1 \\\\ -4 & -2 \\end{pmatrix} \\]\nCheck if A is invertible, and if so, compute the inverse.",
    "a": "Determinant = (2)(-2) - (-4)(1) = -4 + 4 = 0\n\n→ \\mathbf{Not invertible}"
  },
  {
    "q": "Let f(t) = sin²(2t). Find f'(t)",
    "a": "\\[ f'(t) = 2\\sin(2t)\\cdot \\cos(2t) \\cdot 2 = \\mathbf{4\\sin(2t)\\cos(2t)} \\]"
  },
  {
    "q": "Given X = (1, -3, 0, 4), find ||X||₁, ||X||∞, and ||X||₀",
    "a": "- ||X||₁ = 1 + 3 + 0 + 4 = \\mathbf{8}\n- ||X||∞ = \\mathbf{4}\n- ||X||₀ = \\mathbf{3}"
  },
  {
    "q": "Compute the gradient of f(x, y) = (x² + 2y)³",
    "a": "Let f = u³, where u = x² + 2y\nThen:\n\n- \\[ \\frac{∂f}{∂x} = 3u^2 \\cdot 2x = \\mathbf{6x(x^2 + 2y)^2} \\]\n- \\[ \\frac{∂f}{∂y} = 3u^2 \\cdot 2 = \\mathbf{6(x^2 + 2y)^2} \\]\n\nGradient = \\mathbf{(6x(x^2 + 2y)^2, 6(x^2 + 2y)^2)}"
  },
  {
    "q": "A classifier returns the following confusion matrix:\n\n|        | Actual + | Actual – |\n| ------ | -------- | -------- |\n| Pred + | 40       | 10       |\n| Pred – | 20       | 30       |\n\nCompute:\na) Precision\nb) Recall\nc) F1-score",
    "a": "- Precision = 40 / (40 + 10) = \\mathbf{0.80}\n- Recall = 40 / (40 + 20) = \\mathbf{0.666}\n- F1 = 2(0.8 × 0.666)/(0.8 + 0.666) ≈ \\mathbf{0.727}"
  },
  {
    "q": "You are given 4 points:\nA: (1,1), B: (1,2), C: (5,5), D: (6,5)\n\nUsing single linkage and Euclidean distance, which two points merge first?",
    "a": "Distance(A,B) = 1\nDistance(C,D) = 1\nAll other distances > 1\n\n→ \\mathbf{A and B} or \\mathbf{C and D} merge first.\n\nAccept either pair."
  },
  {
    "q": "Run 1 iteration of K-Means on:\nPoints: (1,1), (1,2), (5,5), (6,5)\nInitial centroids: μ₁ = (1,1), μ₂ = (6,5)\n\nAssign points to clusters and compute new centroids.",
    "a": "Assignments:\n- (1,1) → μ₁\n- (1,2) → μ₁\n- (5,5) → μ₂\n- (6,5) → μ₂\n\nNew centroids:\n- μ₁ = ((1+1)/2, (1+2)/2) = \\mathbf{(1, 1.5)}\n- μ₂ = ((5+6)/2, (5+5)/2) = \\mathbf{(5.5, 5)}"
  },
  {
    "q": "Run one iteration of gradient descent for loss L = ½(wx + b - y)²\nGiven: w = 1, x = 2, b = 0, y = 5, η = 0.1",
    "a": "Pred = 1*2 + 0 = 2\nError = 2 - 5 = -3\n\n\\[ w' = w - \\eta \\cdot \\text{error} \\cdot x = 1 - 0.1 \\cdot (-3) \\cdot 2 = 1 + 0.6 = \\mathbf{1.6} \\]\n\\[ b' = b - \\eta \\cdot \\text{error} = 0 + 0.3 = \\mathbf{0.3} \\]"
  },
  {
    "q": "In a dataset of 1000 emails, \"discount\" appears 20 times in spam (100 total spam), and 5 times in ham (900 ham emails).\nUsing Laplace smoothing, estimate:\nP(discount | spam), P(discount | ham)\nVocabulary size = 1000",
    "a": "- Spam: (20 + 1)/(100 + 1000) = 21/1100 ≈ \\mathbf{0.019}\n- Ham: (5 + 1)/(900 + 1000) = 6/1900 ≈ \\mathbf{0.003}"
  },
  {
    "q": "Compute PageRank after one iteration with damping d = 0.85, equal initial score 1/3 each, and graph:\nA → B\nB → C\nC → A",
    "a": "PageRank of A = (1-d)/3 + d * PR(C)\n= 0.05 + 0.85 * (1/3) = 0.05 + 0.283 = \\mathbf{0.333}\n\nSame for B and C due to symmetry.\n\nAnswer: \\mathbf{All nodes remain at 0.333}"
  },
  {
    "q": "In a graph with 5 nodes, node D is reachable from 3 nodes with avg. distance 2. Compute proximity prestige.",
    "a": "Influence fraction = 3/4 = 0.75\nAvDist = 2\nPP = 0.75 / 2 = \\mathbf{0.375}"
  },
  {
    "q": "Find eigenvalues of:\n\\[ A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\]",
    "a": "Det(λI - A) = (λ - 2)² - 1 = λ² - 4λ + 3\nRoots = λ = \\mathbf{1} and \\mathbf{3}"
  },
  {
    "q": "Run 1 round of Apriori with f = 0.5 on:\n\nTransactions:\nT1: A, B\nT2: A, C\nT3: A, B\nT4: B, C\n\nFind frequent 1-itemsets and 2-itemsets.",
    "a": "Support:\nA = 3/4\nB = 3/4\nC = 2/4\n\nPairs:\nAB = 2/4\nAC = 1/4\nBC = 1/4\n\nFrequent 1-itemsets: \\mathbf{A, B}\nFrequent 2-itemsets: \\mathbf{AB}"
  },
  {
    "q": "Use Naive Bayes to classify test: F1=a, F2=c\nData:\n\n| F1  | F2  | Label |\n| --- | --- | ----- |\n| a   | c   | +     |\n| b   | c   | +     |\n| a   | b   | -     |\n| b   | b   | -     |\n\nVocabulary size = 2 per feature",
    "a": "Class +:\n- P(+) = 2/4\n- P(F1=a|+) = 1+1 / (2+2) = 2/4 = 0.5\n- P(F2=c|+) = 2+1 / (2+2) = 3/4\n\nClass –:\n- P(–) = 2/4\n- P(F1=a|–) = 1+1 / (2+2) = 2/4 = 0.5\n- P(F2=c|–) = 0+1 / (2+2) = 1/4\n\nCompute proportional scores:\n- +: 0.5 × 0.5 × 0.75 = 0.1875\n- –: 0.5 × 0.5 × 0.25 = 0.0625\n→ Predict \\mathbf{+}"
  }
]
