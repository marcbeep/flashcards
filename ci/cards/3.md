Q: What does “learning” mean for a neural network?
A: A neural network **learns** by adapting its internal parameters (e.g., synaptic weights) to improve performance.

- Environment supplies stimulation → network processes it.
- In **training mode**, parameters are updated.
- In **online (deployment) mode**, the adapted parameters generate improved responses.

---

Q: How can learning processes in neural networks be classified?
A: - **By learning rules**: mechanisms that update weights (e.g., error-correction, Hebbian).

- **By paradigms**: ways data is presented (supervised, unsupervised, reinforcement).

---

Q: Describe error-correction learning and give its key formulas.
A: - Compares actual output \( y_k(n) \) to desired \( d_k(n) \); error \( e_k(n) = d_k(n) - y_k(n) \).

- **Delta (Widrow–Hoff) rule** updates weights:  
  \[ \Delta w\_{kj}(n) = \eta\, e_k(n)\, x_j(n) \]
- Learning minimizes cost \( E(n) = \frac{1}{2} e_k^2(n) \).

---

Q: What is memory-based learning and how is a prediction made?
A: - Stores the entire training set \( D\_{\text{train}} = \{(x_i,d_i)\} \).

- For a test sample, retrieves the closest stored input (1-NN):  
  \[ x^\* = \arg\min*{x \in D*{\text{train}}} \|x - x\_{\text{test}}\|\_2 \]
- Predicts using the corresponding stored output \( d^\* \); extends to k-NN, weighted k-NN, Parzen windows.

---

Q: State the Hebbian learning principle, its weight update, and a stabilization variant.
A: - Principle: “Neurons that fire together, wire together.”

- Basic update:  
  \[ \Delta w\_{kj}(n) = \eta\, y_k(n)\, x_j(n) \]
- Limitation: unbounded growth (synaptic saturation).
- **Covariance hypothesis** stabilizes weights:  
  \[ \Delta w\_{kj}(n) = \eta\, (y_k - \bar{y})(x_j - \bar{x}) \]

---

Q: How does competitive learning work and which formulas govern it?
A: - Neurons compete; only the **winner** fires:  
 \[ y_k=\begin{cases}1 & v_k > v_j,\ \forall j\neq k\\0&\text{otherwise}\end{cases} \]

- Winner’s weights move toward the input:  
  \[ \Delta w*{ki} = \eta (x_i - w*{ki}) \]
- Produces specialization for clustering and Self-Organizing Maps.

---

Q: Outline Boltzmann learning, including energy, state update probability, and weight rule.
A: - Uses binary (\(+1/-1\)) units and an **energy function**:  
 \[ E = -\frac{1}{2} \sum*{k\neq j} w*{kj} x_k x_j \]

- State flip probability:  
  \[ p(x_k \!\to\! -x_k) = \frac{1}{1 + \exp(-\Delta E_k / T)} \]
- Weight update from clamped vs. free correlations:  
  \[ \Delta w*{kj} = \eta\bigl(\rho^+*{kj} - \rho^-\_{kj}\bigr) \]

---

Q: What is the credit assignment problem in neural networks?
A: Identifying which internal decisions should receive credit/blame for an outcome.

- **Temporal credit assignment**: pinpointing the responsible time step.
- **Structural credit assignment**: pinpointing the responsible neuron/layer.

---

Q: Summarize supervised learning and its training dataset notation.
A: - Learns from labeled pairs \( (x*i,d_i) \) in \( D*{\text{train}} \).

- Minimizes error between network output and desired output.
- After training, operates without the teacher.

---

Q: Describe unsupervised learning and give a classic example.
A: - Uses only input data (no labels) to uncover structure (e.g., clusters, features).

- **Competitive learning** and k-NN are typical methods.

---

Q: Explain reinforcement learning, its objective, and main components.
A: - Agent interacts with an environment: observes state, takes action, receives reward.

- Objective: **maximize cumulative (long-term) reward**.
- Components:
  - **Policy**: maps states to actions.
  - **Learning algorithm**: updates the policy via trial-and-error.

---

Q: Compare supervised, unsupervised, and reinforcement learning on teacher presence, feedback, and goal.
A: - **Supervised**

- Teacher: Yes
- Feedback: error signal
- Goal: learn input–output mapping
- **Unsupervised**
  - Teacher: No
  - Feedback: data statistics/structure
  - Goal: discover hidden patterns/features
- **Reinforcement**
  - Teacher: No
  - Feedback: scalar reward signal
  - Goal: maximize cumulative reward

---
