---
## üß† Characteristics & Structure of MLPs

### ‚úÖ Key Features:

1. **Nonlinear Activation Functions**:
  - E.g., Logistic sigmoid, hyperbolic tangent (tanh).
  - Allow approximation of complex, non-linear relationships.
  - Must be smooth and differentiable for gradient-based learning.

2. **Hidden Layers**:
  - Enable MLPs to learn **composite features**.
  - Essential for solving **non-linearly separable problems** (e.g., XOR).
  - Each hidden layer progressively extracts more abstract representations.

3. **Full Connectivity**:
  - Each neuron receives input from **all neurons** in the previous layer.
  - Only forward connections (no feedback loops).
---

## üîç Function of Hidden Layers

- Solve complex problems by **combining partial solutions** across neurons.
- Hidden layers let MLPs form **non-linear decision boundaries**.
- The more layers, the more **complex patterns** the network can capture (deep learning).

---

## üîÑ Backpropagation Algorithm (BP)

### 1. **Core Idea**:

- BP trains MLPs using **gradient descent**.
- Minimizes an error function by adjusting weights via **partial derivatives**.

### 2. **Error Definitions**:

- Output neuron error:

  $$
  e_j(n) = d_j(n) - y_j(n)
  $$

- Network error (for one pattern):

  $$
  E(n) = \frac{1}{2} \sum_j e_j^2(n)
  $$

- Average error across data:

  $$
  E_{\text{avg}} = \frac{1}{N} \sum_{n=1}^N E(n)
  $$

### 3. **Forward Pass**:

- Compute each neuron‚Äôs output:

  $$
  v_j(n) = \sum_i w_{ji}(n) y_i(n), \quad y_j(n) = \phi_j(v_j(n))
  $$

### 4. **Backward Pass**:

- Compute gradients:

  - **Output layer**:

    $$
    \delta_j(n) = e_j(n) \phi'_j(v_j(n))
    $$

  - **Hidden layer**:

    $$
    \delta_j(n) = \phi'_j(v_j(n)) \sum_k \delta_k(n) w_{kj}(n)
    $$

- Weight update:

  $$
  \Delta w_{ji}(n) = \eta \delta_j(n) y_i(n)
  $$

---

## üî¢ Activation Functions in BP

| Function    | Formula                       | Derivative (used in BP)                 |
| ----------- | ----------------------------- | --------------------------------------- |
| **Sigmoid** | $\frac{1}{1 + e^{-\alpha v}}$ | $\alpha y (1 - y)$                      |
| **Tanh**    | $\alpha \tanh(\beta v)$       | $\frac{\beta}{\alpha} (\alpha^2 - y^2)$ |

---

## üèãÔ∏è‚Äç‚ôÇÔ∏è Training Modes

1. **Sequential Training (STM)**:

   - Updates weights after each pattern.
   - Less memory, can escape local minima.

2. **Batch Training (BTM)**:

   - Updates after all patterns (epoch).
   - Easier to parallelize and analyze.

3. **Mini-Batch Training (MBTM)**:

   - Standard method today.
   - Balance between STM and BTM.

---

## ‚ö° Learning Speed

- **Learning Rate $\eta$**:

  - Controls weight update size.
  - Small $\eta$: slow, stable. Large $\eta$: fast, risky.

- **Momentum $\mu$**:

  - Adds previous weight update to current one:

    $$
    \Delta w_{ji}(n) = \eta \delta_j(n) y_i(n) + \mu \Delta w_{ji}(n - 1)
    $$

  - Helps escape shallow minima, reduces oscillations.

---

## üß© Generalization & Complexity Control

### ‚ö†Ô∏è Overfitting Risks:

- High-capacity MLPs (many layers) may learn noise in training data.

### ‚úÖ Good Practices:

1. **Data Splitting**:

   - **Training set**: updates weights.
   - **Validation set**: tunes hyperparameters.
   - **Test set**: evaluates final performance.

2. **Early Stopping**:

   - Monitor validation error.
   - Stop when it **increases** (indicates overfitting).

---

## üõ°Ô∏è Regularization Techniques

### 1. **General Formula**:

$$
E(\mathbf{w}) = E_{\text{avg}}(\mathbf{w}) + \lambda E_S(\mathbf{w})
$$

### 2. **Types**:

| Technique                       | Description                                                                  |
| ------------------------------- | ---------------------------------------------------------------------------- |
| **Weight Decay**                | Penalize large weights: $E_S = \sum_i w_i^2$                                 |
| **Penalty on Derivatives**      | Penalize lack of smoothness: minimize high-order derivatives of MLP function |
| **Weight Elimination**          | Soft penalty: small weights discouraged more than large ones                 |
| **Dropout**                     | Randomly deactivate neurons during training ‚Üí train multiple subnetworks     |
| **Optimal Brain Damage (OBD)**  | Uses Hessian of error surface to prune least important weights               |
| **Optimal Brain Surgeon (OBS)** | Full-Hessian version of OBD for better precision in pruning                  |

---

## üß† Final Takeaway

Training MLPs using BP involves:

- A **clear learning rule (BP)** with forward and backward passes.
- Selection of **appropriate activation functions**.
- Choices in **training mode** and **learning rate** tuning.
- Avoiding overfitting via:

  - **Early stopping**
  - **Dropout**
  - **Regularization**
  - **Weight pruning (OBD/OBS)**

These concepts are the **foundation of modern neural networks** and remain essential in deep learning frameworks today.

---
