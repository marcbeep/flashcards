---

## üß¨ **Evolution Strategies (ES) - Summary**

### üîπ Overview

- **ES** is one of the earliest evolutionary algorithms designed for **numerical optimization** (finding minimum/maximum values of functions).
- It uses **real-valued solutions** and works by exploring the solution space using **mutation only**‚Äîno crossover or selection pressure in the basic version.
- Can operate with a **very small population**, even just **1 parent + 1 child** (called **(1+1)-ES**).
- The search process is:

  1. Start from an initial point $x^{(0)}$
  2. Add a random change: $x^{(t+1)} = x^{(t)} + r$ where $r \sim \mathcal{N}(0, \Sigma)$
  3. Accept the new point if it improves the objective $F$, otherwise stay with the current one

---

### üîπ Encoding

Each solution is encoded as:

$$
(x, \Sigma) = [x_1, ..., x_d, \sigma_1, ..., \sigma_k] \quad \text{where } k = \frac{d(d+1)}{2}
$$

- $\Sigma$ is the **covariance matrix**:

  - Diagonal = step sizes (variances)
  - Off-diagonal = rotation angles (correlation between variables)

- Both $x$ and $\Sigma$ can **co-evolve** ‚Äî the algorithm adapts its search strategy over time.

Basic mutation:

$$
x^{(t+1)} = x^{(t)} + \mathcal{N}(0, \Sigma^{(t)}), \quad \Sigma^{(t+1)} = \Sigma^{(t)} = \sigma I
$$

This is a **simple case** where the step size is fixed and the same in all directions.

---

### üîπ Theoretical Result

$$
\lim_{t \to \infty} F(x^{(t)}) = F(x_{\text{optimal}})
$$

- The algorithm **will eventually reach** the optimal value.
- But this doesn't help estimate how long it will take ‚Äî hence, extensions are introduced.

---

## üîß Extensions to Improve ES

### 1Ô∏è‚É£ **The 1/5 Success Rule**

- **Goal**: Automatically adjust mutation strength based on recent performance.
- **Rule**: If more than 1 in 5 mutations are successful (i.e. improve the solution), the step size is **too small** ‚Üí **increase it**. Otherwise, **decrease it**.

Update formula:

$$
\sigma^{(t+1)} =
\begin{cases}
c_{\text{dec}} \cdot \sigma^{(t)} & \text{if } R_k < 1/5 \\
c_{\text{inc}} \cdot \sigma^{(t)} & \text{if } R_k > 1/5 \\
\sigma^{(t)} & \text{if } R_k = 1/5
\end{cases}
$$

- Typical constants: $c_{\text{inc}} = 1.22$, $c_{\text{dec}} \in [0.8, 1.0]$

---

### 2Ô∏è‚É£ **(Œº+Œª)-ES**

- Use **Œº parents** to produce **Œª offspring**.
- Then select the best **Œº individuals** from the **combined pool (Œº + Œª)** for the next generation.
- Keeps **strong parents alive** longer.

‚úîÔ∏è Helps avoid premature convergence.

---

### 3Ô∏è‚É£ **(Œº,Œª)-ES**

- Again, Œº parents produce Œª children.
- But now select the **next generation only from the Œª offspring**.
- Each individual lives only **one generation**.

‚úîÔ∏è Better for **dynamic or noisy** environments.

---

### 4Ô∏è‚É£ **ES with Crossover**

- Like Genetic Algorithms, ES can use **crossover** to combine two parents.

Each parent looks like:

$$
[x_1, \Sigma_1] = [x_{11}, ..., x_{1d}, \sigma_{11}, ..., \sigma_{1k}]
$$

$$
[x_2, \Sigma_2] = [x_{21}, ..., x_{2d}, \sigma_{21}, ..., \sigma_{2k}]
$$

- Crossover types:

  - **Discrete crossover** (e.g., uniform or 2-point)
  - **Real-valued crossover** (e.g., average values)

After crossover, **mutation** is applied.

‚ö†Ô∏è Must ensure the **covariance matrix stays valid**.

---

### 5Ô∏è‚É£ **Updating the Covariance Matrix (Full Form)**

To evolve the **strategy itself**, update both diagonal and off-diagonal elements of Œ£:

- **Update variances**:

  $$
  \sigma_{ii}^{(t+1)} = \sigma_{ii}^{(t)} \cdot e^{N(0, \Delta\sigma)}
  $$

- **Update rotation angles**:

  $$
  \alpha_{ij}^{(t+1)} = \alpha_{ij}^{(t)} + N(0, \Delta\alpha) \quad \text{for } i \ne j
  $$

- Then:

  $$
  x^{(t+1)} = x^{(t)} + \mathcal{N}(0, \Sigma^{(t+1)})
  $$

- **Covariance matrix**:

  $$
  \Sigma =
  \begin{bmatrix}
  \sigma_{11} & \dots & \sigma_{1d} \\
  \vdots & \ddots & \vdots \\
  \sigma_{d1} & \dots & \sigma_{dd}
  \end{bmatrix}
  $$

- Rotation angle formula:

  $$
  \tan(2\alpha_{ij}) = \frac{2\sigma_{ij}}{\sigma_{ii} - \sigma_{jj}}
  $$

---

## üßÅ Summary Table

| Feature            | Purpose / Behavior                              |
| ------------------ | ----------------------------------------------- |
| (1+1)-ES           | Simple: 1 parent, 1 child, accept if better     |
| 1/5 Rule           | Adjust step size based on success rate          |
| (Œº+Œª)-ES           | Keep best Œº from Œº + Œª (parents and children)   |
| (Œº,Œª)-ES           | Keep best Œº from children only                  |
| Crossover          | Combine traits from two parents before mutation |
| Covariance Updates | Adapt how mutation behaves, including direction |

---
