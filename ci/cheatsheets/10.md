---
# üß¨ **Genetic Algorithms (GAs) ‚Äì Overview and Key Concepts**
---

## üîç What Are Genetic Algorithms?

Genetic Algorithms (GAs) are **search and optimization techniques** inspired by the process of **natural evolution** (like Darwin‚Äôs natural selection). They simulate how living things evolve to find better solutions over generations.

- They use ideas from **genetics**: selection, crossover, mutation.
- They work with a **population** of candidate solutions.
- Each solution is like an **individual**, with:

  - **Genotype**: encoded string (e.g. binary)
  - **Phenotype**: actual result (e.g. a number or path)

---

## ‚öôÔ∏è Main Stages in a Genetic Algorithm

1. **Genetic Coding**

   - Convert each possible solution into a "chromosome" (e.g., a binary string).

2. **Population**

   - A group of solutions is maintained. Should be large enough for variety, but small enough for speed.

3. **Fitness Evaluation**

   - Check how good each solution is by computing a **fitness score**.

4. **Selection**

   - Better solutions are more likely to be chosen to create new ones. (Fitness-proportionate selection is common.)

5. **Crossover**

   - Combine parts of two parent solutions to form children. Helps **exploit** good solutions.

6. **Mutation**

   - Randomly flip bits in children to introduce variety. Helps **explore** new possibilities.

7. **Replacement**

   - New children replace the old population, and the process repeats.

---

## üìâ Genetic Encoding (Binary)

- Variables are encoded as binary strings.
- Each variable `x·µ¢` in a range `[x·µ¢,min, x·µ¢,max]` is represented using `l‚ÇÄ` bits.
- Decoding:

  $$
  x·µ¢ = x·µ¢,min + \left( \frac{x·µ¢,max - x·µ¢,min}{2^{l‚ÇÄ} - 1} \right) √ó D
  $$

  where `D` is the decimal value of the binary string.

- The **precision** depends on `l‚ÇÄ` ‚Äî more bits = finer granularity.

---

## üß± Chromosome Shapes & Crossover Types

GAs can use **non-string structures** like:

- **(A)** 1D string ‚Üí 3-point crossover
- **(B)** 2D matrix ‚Üí row-based crossover
- **(C)** 2D matrix ‚Üí two-line crossover
- **(D)** Graph ‚Üí subgraph crossover
- **(E)** Set ‚Üí subset crossover

This flexibility allows GAs to solve **complex, structured problems**.

---

## üîÄ Crossover ‚Äì Mixing Genes

- Purpose: **Exploit good solutions** by combining parent traits.
- Random crossover point chosen.
- Produces two children from parts of two parents.

**Example**:

| Parent 1 | 001000‚Äñ0010 |
| -------- | ----------- |
| Parent 2 | 001100‚Äñ1100 |

‚Üí Children:

- Child 1: `0010001100`
- Child 2: `0011000010`

‚ö†Ô∏è Too much similarity between parents can hurt diversity.

---

## ‚ö° Mutation ‚Äì Adding Randomness

- Purpose: **Explore** new areas, maintain diversity.
- Small chance for each bit to flip (e.g., 1 ‚Üí 0).
- Prevents the algorithm from getting **stuck** with "almost good" solutions.

**Example**:

Before:

- `0010001100` ‚Üí
- `0011000010`

After mutation:

- `0010101100`
- `0001000010`

‚ö†Ô∏è Mutation rate must be low ‚Äî too high makes the search random.

---

## ‚úÖ Advantages of Genetic Algorithms

- Work well with both **continuous and discrete problems**.
- Handle **discontinuous, noisy, and complex search spaces**.
- Can **search many solutions at once** (population-based).
- Work even when calculus-based methods don‚Äôt.
- Useful in a wide range of applications:

  - Machine learning
  - Game playing
  - NP-hard problems
  - Adaptive control systems

---

## ‚ö†Ô∏è Drawbacks of Genetic Algorithms

- **No guarantee of convergence** (may not find the best solution).
- Can be **slow** for complex problems.
- Needs **careful tuning** (mutation rate, population size, etc.).
- General GAs are often **less efficient** than problem-specific ones.
- Risk of **premature convergence** if diversity is lost.

---

## üéØ Final Thoughts

Genetic Algorithms are **powerful and flexible**, especially for problems that are too hard for traditional methods.
But they require **careful design**, a good balance between **exploration (mutation)** and **exploitation (crossover)**, and **parameter tuning** for best performance.

---

# Example GA:

```python
import random

# Target number we want to reach
TARGET = 2001

# Genetic Algorithm parameters
POPULATION_SIZE = 10
MUTATION_RATE = 0.1
GENERATIONS = 50


# Create a random individual (a number between 0 and 4000)
def create_individual():
    return random.randint(0, 4000)


# Create the initial population
def create_population():
    return [create_individual() for _ in range(POPULATION_SIZE)]


# Fitness function: higher is better
def fitness(individual):
    return 1 / (1 + abs(TARGET - individual))


# Select parents using fitness-proportionate selection
def select_parents(population):
    total_fitness = sum(fitness(ind) for ind in population)
    probabilities = [fitness(ind) / total_fitness for ind in population]
    return random.choices(population, weights=probabilities, k=2)


# Crossover: average of two parents
def crossover(parent1, parent2):
    return (parent1 + parent2) // 2


# Mutation: small random change
def mutate(individual):
    if random.random() < MUTATION_RATE:
        change = random.randint(-10, 10)
        return max(0, individual + change)
    return individual


# Run the Genetic Algorithm
def run_ga():
    population = create_population()
    best_solution = None
    best_fitness = 0

    print(f"Starting Genetic Algorithm to find number closest to {TARGET}")
    print("-" * 50)

    for generation in range(GENERATIONS):
        new_population = []
        for _ in range(POPULATION_SIZE):
            parent1, parent2 = select_parents(population)
            child = crossover(parent1, parent2)
            child = mutate(child)
            new_population.append(child)

        population = new_population
        best_solution = max(population, key=fitness)
        current_fitness = fitness(best_solution)

        if current_fitness > best_fitness:
            best_fitness = current_fitness
            print(
                f"Generation {generation + 1}: New best solution = {best_solution} (fitness: {best_fitness:.4f})"
            )

    print("-" * 50)
    print(f"Final result: {best_solution}")
    print(f"Distance from target: {abs(TARGET - best_solution)}")
    return best_solution


if __name__ == "__main__":
    best = run_ga()
```
