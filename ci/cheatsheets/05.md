---
## ðŸ§  Characteristics & Structure of MLPs

### âœ… Key Features:

1. **Nonlinear Activation Functions**:
  - E.g., Logistic sigmoid, hyperbolic tangent (tanh).
  - Allow approximation of complex, non-linear relationships.
  - Must be smooth and differentiable for gradient-based learning.

2. **Hidden Layers**:
  - Enable MLPs to learn **composite features**.
  - Essential for solving **non-linearly separable problems** (e.g., XOR).
  - Each hidden layer progressively extracts more abstract representations.

3. **Full Connectivity**:
  - Each neuron receives input from **all neurons** in the previous layer.
  - Only forward connections (no feedback loops).
---

## ðŸ” Function of Hidden Layers

- Solve complex problems by **combining partial solutions** across neurons.
- Hidden layers let MLPs form **non-linear decision boundaries**.
- The more layers, the more **complex patterns** the network can capture (deep learning).

---

## ðŸ”„ Backpropagation Algorithm (BP)

### 1. **Core Idea**:

- BP trains MLPs using **gradient descent**.
- Minimizes an error function by adjusting weights via **partial derivatives**.

### 2. **Error Definitions**:

- Output neuron error:

  $$
  e_j(n) = d_j(n) - y_j(n)
  $$

- Network error (for one pattern):

  $$
  E(n) = \frac{1}{2} \sum_j e_j^2(n)
  $$

- Average error across data:

  $$
  E_{\text{avg}} = \frac{1}{N} \sum_{n=1}^N E(n)
  $$

### 3. **Forward Pass**:

- Compute each neuronâ€™s output:

  $$
  v_j(n) = \sum_i w_{ji}(n) y_i(n), \quad y_j(n) = \phi_j(v_j(n))
  $$

### 4. **Backward Pass**:

- Compute gradients:

  - **Output layer**:

    $$
    \delta_j(n) = e_j(n) \phi'_j(v_j(n))
    $$

  - **Hidden layer**:

    $$
    \delta_j(n) = \phi'_j(v_j(n)) \sum_k \delta_k(n) w_{kj}(n)
    $$

- Weight update:

  $$
  \Delta w_{ji}(n) = \eta \delta_j(n) y_i(n)
  $$

---

## ðŸ”¢ Activation Functions in BP

| Function    | Formula                       | Derivative (used in BP)                 |
| ----------- | ----------------------------- | --------------------------------------- |
| **Sigmoid** | $\frac{1}{1 + e^{-\alpha v}}$ | $\alpha y (1 - y)$                      |
| **Tanh**    | $\alpha \tanh(\beta v)$       | $\frac{\beta}{\alpha} (\alpha^2 - y^2)$ |

---

## ðŸ‹ï¸â€â™‚ï¸ Training Modes

1. **Sequential Training (STM)**:

   - Updates weights after each pattern.
   - Less memory, can escape local minima.

2. **Batch Training (BTM)**:

   - Updates after all patterns (epoch).
   - Easier to parallelize and analyze.

3. **Mini-Batch Training (MBTM)**:

   - Standard method today.
   - Balance between STM and BTM.

---

## âš¡ Learning Speed

- **Learning Rate $\eta$**:

  - Controls weight update size.
  - Small $\eta$: slow, stable. Large $\eta$: fast, risky.

- **Momentum $\mu$**:

  - Adds previous weight update to current one:

    $$
    \Delta w_{ji}(n) = \eta \delta_j(n) y_i(n) + \mu \Delta w_{ji}(n - 1)
    $$

  - Helps escape shallow minima, reduces oscillations.

---

## ðŸ§© Generalization & Complexity Control

### âš ï¸ Overfitting Risks:

- High-capacity MLPs (many layers) may learn noise in training data.

### âœ… Good Practices:

1. **Data Splitting**:

   - **Training set**: updates weights.
   - **Validation set**: tunes hyperparameters.
   - **Test set**: evaluates final performance.

2. **Early Stopping**:

   - Monitor validation error.
   - Stop when it **increases** (indicates overfitting).

---

## ðŸ›¡ï¸ Regularization Techniques

### 1. **General Formula**:

$$
E(\mathbf{w}) = E_{\text{avg}}(\mathbf{w}) + \lambda E_S(\mathbf{w})
$$

### 2. **Types**:

| Technique                       | Description                                                                  |
| ------------------------------- | ---------------------------------------------------------------------------- |
| **Weight Decay**                | Penalize large weights: $E_S = \sum_i w_i^2$                                 |
| **Penalty on Derivatives**      | Penalize lack of smoothness: minimize high-order derivatives of MLP function |
| **Weight Elimination**          | Soft penalty: small weights discouraged more than large ones                 |
| **Dropout**                     | Randomly deactivate neurons during training â†’ train multiple subnetworks     |
| **Optimal Brain Damage (OBD)**  | Uses Hessian of error surface to prune least important weights               |
| **Optimal Brain Surgeon (OBS)** | Full-Hessian version of OBD for better precision in pruning                  |

---

## ðŸ§  Final Takeaway

Training MLPs using BP involves:

- A **clear learning rule (BP)** with forward and backward passes.
- Selection of **appropriate activation functions**.
- Choices in **training mode** and **learning rate** tuning.
- Avoiding overfitting via:

  - **Early stopping**
  - **Dropout**
  - **Regularization**
  - **Weight pruning (OBD/OBS)**

These concepts are the **foundation of modern neural networks** and remain essential in deep learning frameworks today.

---

# Plain English Backprop Example

---

## ðŸŽ¯ Problem Setup (Simple Neural Network)

- **Inputs**: $x_1 = 0.6$, $x_2 = 0.2$
- **Hidden weights**: $w_{h1} = 0.5$, $w_{h2} = 0.4$
- **Output weight**: $w_{ho} = 0.9$
- **Target output**: $d = 1$
- **Learning rate**: $\eta = 0.1$

---

## â–¶ï¸ Step 1: **Forward Pass** (Make a guess)

### ðŸ§® Hidden Neuron (before activation)

$$
v_h = x_1 \cdot w_{h1} + x_2 \cdot w_{h2} = 0.6 \cdot 0.5 + 0.2 \cdot 0.4 = 0.3 + 0.08 = 0.38
$$

> **English**: Multiply inputs by their weights and add them up.

### ðŸ”„ Apply sigmoid activation

$$
y_h = \frac{1}{1 + e^{-v_h}} = \frac{1}{1 + e^{-0.38}} \approx 0.594
$$

> **English**: Plug the result into the sigmoid function to get the hidden neuronâ€™s output.

---

### ðŸ§® Output Neuron (before activation)

$$
v_o = y_h \cdot w_{ho} = 0.594 \cdot 0.9 = 0.534
$$

> **English**: Multiply the hidden output by its weight to the output.

### ðŸ”„ Apply sigmoid activation

$$
y_o = \frac{1}{1 + e^{-v_o}} = \frac{1}{1 + e^{-0.534}} \approx 0.630
$$

> **English**: Use sigmoid again to get the networkâ€™s final output.

---

## âŒ Step 2: **Calculate Error**

$$
e = d - y_o = 1 - 0.630 = 0.370
$$

> **English**: Subtract the actual output from the target.

$$
E = \frac{1}{2} \cdot e^2 = \frac{1}{2} \cdot (0.370)^2 = 0.0685
$$

> **English**: Square the error and divide by 2 (this is the total error for this example).

---

## ðŸ” Step 3: **Backward Pass** (Figure out how wrong the weights are)

### ðŸ”½ Output Neuron Delta (how much to change)

$$
\phi'(v_o) = y_o \cdot (1 - y_o) = 0.630 \cdot (1 - 0.630) = 0.233
$$

> **English**: Compute the derivative of sigmoid using the output.

$$
\delta_o = e \cdot \phi'(v_o) = 0.370 \cdot 0.233 = 0.086
$$

> **English**: Multiply the error by the derivative to get the correction term for the output.

---

### ðŸ”½ Hidden Neuron Delta

$$
\phi'(v_h) = y_h \cdot (1 - y_h) = 0.594 \cdot (1 - 0.594) = 0.241
$$

> **English**: Derivative of sigmoid for the hidden neuron.

$$
\delta_h = \phi'(v_h) \cdot (\delta_o \cdot w_{ho}) = 0.241 \cdot (0.086 \cdot 0.9) = 0.241 \cdot 0.0774 \approx 0.019
$$

> **English**: Use output delta and weight to backtrack the error into the hidden layer.

---

## ðŸ”§ Step 4: **Update the Weights**

### ðŸ”„ Output weight:

$$
\Delta w_{ho} = \eta \cdot \delta_o \cdot y_h = 0.1 \cdot 0.086 \cdot 0.594 = 0.0051
$$

> **English**: Small change to output weight = learning rate Ã— output delta Ã— hidden output

$$
w_{ho}^{new} = 0.9 + 0.0051 = 0.9051
$$

> **English**: Add the small change to the old weight

---

### ðŸ”„ Hidden weight 1:

$$
\Delta w_{h1} = \eta \cdot \delta_h \cdot x_1 = 0.1 \cdot 0.019 \cdot 0.6 = 0.00114
$$

$$
w_{h1}^{new} = 0.5 + 0.00114 = 0.50114
$$

> **English**: Update input-to-hidden weight using input $x_1$

---

### ðŸ”„ Hidden weight 2:

$$
\Delta w_{h2} = 0.1 \cdot 0.019 \cdot 0.2 = 0.00038
$$

$$
w_{h2}^{new} = 0.4 + 0.00038 = 0.40038
$$

> **English**: Update weight for input $x_2$

---

## âœ… Final Summary (Plain English)

1. **Forward Pass**: Guess the output by passing inputs through the network.
2. **Error**: Measure how far the guess was from the target.
3. **Backward Pass**: Figure out how much each weight contributed to the error.
4. **Update Weights**: Adjust the weights to reduce the error next time.

---
