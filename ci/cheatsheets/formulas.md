# ğŸ”¢ Essential Formulas in Computational Intelligence

## ğŸ§  Neural Networks

### Basic Neuron

- **Neuron Output**: Sum of weighted inputs through activation function
  ```
  y = Ï†(Î£ wáµ¢xáµ¢ + b)
  ```
  where Ï† is activation function, w are weights, x are inputs, b is bias

### Activation Functions

- **Sigmoid**: Smooth, differentiable, outputs between 0 and 1

  ```
  Ï†(v) = 1 / (1 + eâ»áµ›)
  ```

- **Tanh**: Like sigmoid but centered at 0, outputs between -1 and 1

  ```
  Ï†(v) = (eÂ²áµ› - 1) / (eÂ²áµ› + 1)
  ```

- **ReLU**: Simple, fast, helps with vanishing gradient
  ```
  Ï†(v) = max(0, v)
  ```

### Backpropagation

- **Output Layer Error**: Difference between target and actual output

  ```
  Î´â±¼ = (dâ±¼ - yâ±¼) Ã— Ï†'(vâ±¼)
  ```

- **Hidden Layer Error**: Error propagated from next layer

  ```
  Î´â±¼ = Ï†'(vâ±¼) Ã— Î£(Î´â‚–wâ‚–â±¼)
  ```

- **Weight Update**: Learning from errors
  ```
  Î”wáµ¢â±¼ = Î· Ã— Î´â±¼ Ã— yáµ¢
  ```
  where Î· is learning rate

## ğŸ“Š Support Vector Machines

- **Decision Boundary**: Hyperplane separating classes

  ```
  wáµ€x + b = 0
  ```

- **Margin**: Distance to closest data points (support vectors)

  ```
  margin = 2 / ||w||
  ```

- **Kernel Trick**: Transform to higher dimension
  ```
  K(x,y) = Ï†(x)áµ€Ï†(y)
  ```

## ğŸ² Reinforcement Learning

- **Q-Learning Update**: Learn action values

  ```
  Q(s,a) = Q(s,a) + Î±[r + Î³Ã—max(Q(s',a')) - Q(s,a)]
  ```

  where Î± is learning rate, Î³ is discount factor

- **Policy**: Probability of taking action in state
  ```
  Ï€(a|s) = e^(Q(s,a)/Ï„) / Î£(e^(Q(s,a')/Ï„))
  ```
  where Ï„ is temperature parameter

## ğŸ§¬ Genetic Algorithms

- **Selection Probability**: Chance of being selected based on fitness

  ```
  p(i) = f(i) / Î£f(j)
  ```

- **Rank-Based Selection**: Selection based on rank instead of raw fitness
  ```
  p(i) = (2-s)/N + 2i(s-1)/(N(N-1))
  ```
  where s is selection pressure

## ğŸ¦ Particle Swarm Optimization

- **Velocity Update**: How particles move in search space

  ```
  v = wÃ—v + câ‚râ‚(pbest - x) + câ‚‚râ‚‚(gbest - x)
  ```

  where w is inertia, câ‚,câ‚‚ are learning factors

- **Position Update**: New position based on velocity
  ```
  x = x + v
  ```

## ğŸ“ˆ Evolution Strategies

- **Mutation**: Gaussian perturbation of solution

  ```
  x' = x + ÏƒÃ—N(0,1)
  ```

  where Ïƒ is step size

- **1/5 Success Rule**: Adapt step size
  ```
  Ïƒ' = Ïƒ Ã— (success_rate > 0.2 ? 1.22 : 0.82)
  ```

## ğŸŒ³ Genetic Programming

- **Tree Size**: Number of nodes in program tree

  ```
  size = 1 + Î£(size of children)
  ```

- **Program Fitness**: Usually includes size penalty
  ```
  fitness = accuracy - Î»Ã—size
  ```
  where Î» controls complexity penalty

## ğŸ” Optimization

- **Gradient Descent**: Basic optimization step

  ```
  x' = x - Î·âˆ‡f(x)
  ```

  where Î· is step size, âˆ‡f is gradient

- **Momentum**: Helps escape local minima
  ```
  v = Î¼v - Î·âˆ‡f(x)
  x' = x + v
  ```
  where Î¼ is momentum coefficient
